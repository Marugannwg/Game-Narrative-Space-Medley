{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_embedding as ce\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit\n",
    "corpus_dir = \"data/Arknights_plot/corpus\"\n",
    "corpus = convokit.model.corpus.Corpus(corpus_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 2031\n",
      "Number of Utterances: 88493\n",
      "Number of Conversations: 6405\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task : create embedding using openAI for ALL utterance\n",
    "\n",
    "This is the sample to use OpenAI embedding model on utterance. It write the embedding into a json file with key to utterance id in real-time.\n",
    "\n",
    "**Warning**: this is the final code I used on the entire dataset, costing around $.34; please try on smaller dataset to avoid unexpected expenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_utterance(client, utterance, model=\"text-embedding-3-large\"):\n",
    "    \"\"\"\n",
    "    Given an utterance, returns the id and the embedding of the utterance\n",
    "    \"\"\"\n",
    "    text = utterance.text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    embedding = response.data[0].embedding\n",
    "    return utterance.id, embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(client, corpus, num_workers=10, model=\"text-embedding-3-large\", output_file=\"utterance_embeddings.json\"):\n",
    "    # Initialize a lock for thread-safe writing to the file\n",
    "    lock = Lock()\n",
    "\n",
    "    # Open the output file in write mode\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('{')  # Start the JSON object\n",
    "\n",
    "    def process_and_write_utterance(client, utterance, model):\n",
    "        utterance_id, embedding = process_utterance(client, utterance, model)\n",
    "        # Convert the embedding to a string representation for JSON\n",
    "        embedding_str = json.dumps(embedding)\n",
    "        # Prepare the JSON entry for this utterance\n",
    "        json_entry = f'\"{utterance_id}\": {embedding_str},'\n",
    "\n",
    "        # Use the lock to ensure thread-safe writing to the file\n",
    "        with lock:\n",
    "            with open(output_file, 'a') as f:\n",
    "                f.write(json_entry)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Create a future for each utterance in the corpus\n",
    "        futures = [executor.submit(process_and_write_utterance, client, utt, model) for utt in corpus.iter_utterances()]\n",
    "\n",
    "        # Use tqdm to create a progress bar\n",
    "        for _ in tqdm(as_completed(futures), total=len(futures), desc=\"Processing Utterances\"):\n",
    "            pass  # Each future writes its result to the file upon completion\n",
    "\n",
    "    # Correct the final JSON format by removing the last comma and closing the JSON object\n",
    "    with open(output_file, 'rb+') as f:\n",
    "        f.seek(-1, 2)  # Go to the last character\n",
    "        f.truncate()  # Remove the last comma\n",
    "        f.write(b'}')  # Close the JSON object\n",
    "\n",
    "    print(f\"Embeddings saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Utterances: 100%|██████████| 88493/88493 [11:29<00:00, 128.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to utterance_embeddings.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "num_workers = 50  # Set the number of workers as desired\n",
    "generate_embeddings(client, corpus, num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, the resulting json is extremly large, using `ijson` to manage it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_embed_dir = \"data\\\\Arknights_plot\\\\embedding\\\\utterance_embeddings.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(utt_embed_dir, 'r') as file:\n",
    "    # Parse the JSON objects one by one\n",
    "    parser = ijson.items(file, 'item')\n",
    "    \n",
    "    # Iterate over the JSON objects\n",
    "    for item in parser:\n",
    "        # Process each JSON object as needed\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result file is VERY LARGE \n",
    "# using ijson to read the file\n",
    "\n",
    "# take a look at the first 5 lines\n",
    "\n",
    "import ijson\n",
    "\n",
    "def read_embeddings(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        keys = ijson.items(f, 'item.key')  # Get all keys\n",
    "        f.seek(0)  # Reset file pointer to the beginning\n",
    "        values = ijson.items(f, 'item.value')  # Get all values\n",
    "\n",
    "        for utterance_id, embedding in zip(keys, values):\n",
    "            print(f\"Utterance ID: {utterance_id}, Embedding: {embedding}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_embeddings(utt_embed_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample usage: A machine learning classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_characters = [\"Amiya\", \"Blaze\", \"Gavial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_embeddings(filename, characters):\n",
    "    filtered_embeddings = {}\n",
    "    with open(filename, 'rb') as f:\n",
    "        keys = ijson.items(f, 'item.key')\n",
    "        f.seek(0)  # Reset file pointer to the beginning\n",
    "        values = ijson.items(f, 'item.value')\n",
    "\n",
    "        for utterance_id, embedding in zip(keys, values):\n",
    "            character_name = utterance_id.split(\"_\")[0]  # Assuming the utterance ID format includes the character name\n",
    "            if character_name in characters:\n",
    "                filtered_embeddings[utterance_id] = embedding\n",
    "    return filtered_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_embeddings = filter_embeddings(utt_embed_dir, interested_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interested_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = []  # Feature matrix\n",
    "y = []  # Labels\n",
    "\n",
    "for utterance_id, embedding in interested_embeddings.items():\n",
    "    character_name = utterance_id.split(\"_\")[0]\n",
    "    X.append(embedding)\n",
    "    y.append(character_name)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training a classifier\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions and evaluating\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i, character in enumerate(interested_characters):\n",
    "    idx = y == character\n",
    "    plt.scatter(X_reduced[idx, 0], X_reduced[idx, 1], label=character)\n",
    "plt.legend()\n",
    "plt.title(\"Character Embeddings Visualization\")\n",
    "plt.xlabel(\"PCA1\")\n",
    "plt.ylabel(\"PCA2\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
