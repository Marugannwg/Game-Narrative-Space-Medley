{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit\n",
    "\n",
    "output_dir = \"D:/MACSS PROGRAM/30122/MACS-60000-2024-Winter/data/Arknights_plot/corpus\"\n",
    "# Load the corpus from the saved directory\n",
    "corpus = convokit.model.corpus.Corpus(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucem_illud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.story</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>utt_0</th>\n",
       "      <td>0</td>\n",
       "      <td>It's been a long time since we've last seen...</td>\n",
       "      <td>non-character</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_0</td>\n",
       "      <td>main_0_Evil Time Part 1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_1</th>\n",
       "      <td>1</td>\n",
       "      <td>...consciousness...    Circulation resumed....</td>\n",
       "      <td>Distant Voice</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_1</td>\n",
       "      <td>main_0_Evil Time Part 1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_2</th>\n",
       "      <td>2</td>\n",
       "      <td>......    Doctor...    ...hand!    Take my....</td>\n",
       "      <td>???</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_1</td>\n",
       "      <td>main_0_Evil Time Part 1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_3</th>\n",
       "      <td>3</td>\n",
       "      <td>Amiya! Don't panic, just calm down first!</td>\n",
       "      <td>Medic</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_1</td>\n",
       "      <td>main_0_Evil Time Part 1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ah... S-sorry.</td>\n",
       "      <td>Amiya</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_1</td>\n",
       "      <td>main_0_Evil Time Part 1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_88488</th>\n",
       "      <td>88488</td>\n",
       "      <td>This mission was originally meant for the La...</td>\n",
       "      <td>???</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_88481</td>\n",
       "      <td>act9mini_Pinus Sylvestris</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_88489</th>\n",
       "      <td>88489</td>\n",
       "      <td>Confirmed... It's a match.</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_88481</td>\n",
       "      <td>act9mini_Pinus Sylvestris</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_88490</th>\n",
       "      <td>88490</td>\n",
       "      <td>Very good.   Do not disappoint us.</td>\n",
       "      <td>???</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_88481</td>\n",
       "      <td>act9mini_Pinus Sylvestris</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_88491</th>\n",
       "      <td>88491</td>\n",
       "      <td>It's easy to make a regular Joe disappear, but...</td>\n",
       "      <td>non-character</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_88491</td>\n",
       "      <td>act9mini_Pinus Sylvestris</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_88492</th>\n",
       "      <td>88492</td>\n",
       "      <td>Hmph...   *Sigh*... Can't I at least get a l...</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_88492</td>\n",
       "      <td>act9mini_Pinus Sylvestris</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88493 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp                                               text  \\\n",
       "id                                                                       \n",
       "utt_0             0     It's been a long time since we've last seen...   \n",
       "utt_1             1     ...consciousness...    Circulation resumed....   \n",
       "utt_2             2     ......    Doctor...    ...hand!    Take my....   \n",
       "utt_3             3          Amiya! Don't panic, just calm down first!   \n",
       "utt_4             4                                     Ah... S-sorry.   \n",
       "...             ...                                                ...   \n",
       "utt_88488     88488    This mission was originally meant for the La...   \n",
       "utt_88489     88489                         Confirmed... It's a match.   \n",
       "utt_88490     88490                 Very good.   Do not disappoint us.   \n",
       "utt_88491     88491  It's easy to make a regular Joe disappear, but...   \n",
       "utt_88492     88492    Hmph...   *Sigh*... Can't I at least get a l...   \n",
       "\n",
       "                 speaker reply_to conversation_id                 meta.story  \\\n",
       "id                                                                             \n",
       "utt_0      non-character     None           utt_0    main_0_Evil Time Part 1   \n",
       "utt_1      Distant Voice     None           utt_1    main_0_Evil Time Part 1   \n",
       "utt_2                ???     None           utt_1    main_0_Evil Time Part 1   \n",
       "utt_3              Medic     None           utt_1    main_0_Evil Time Part 1   \n",
       "utt_4              Amiya     None           utt_1    main_0_Evil Time Part 1   \n",
       "...                  ...      ...             ...                        ...   \n",
       "utt_88488            ???     None       utt_88481  act9mini_Pinus Sylvestris   \n",
       "utt_88489       Platinum     None       utt_88481  act9mini_Pinus Sylvestris   \n",
       "utt_88490            ???     None       utt_88481  act9mini_Pinus Sylvestris   \n",
       "utt_88491  non-character     None       utt_88491  act9mini_Pinus Sylvestris   \n",
       "utt_88492       Platinum     None       utt_88492  act9mini_Pinus Sylvestris   \n",
       "\n",
       "          vectors  \n",
       "id                 \n",
       "utt_0          []  \n",
       "utt_1          []  \n",
       "utt_2          []  \n",
       "utt_3          []  \n",
       "utt_4          []  \n",
       "...           ...  \n",
       "utt_88488      []  \n",
       "utt_88489      []  \n",
       "utt_88490      []  \n",
       "utt_88491      []  \n",
       "utt_88492      []  \n",
       "\n",
       "[88493 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_df = corpus.get_utterances_dataframe()\n",
    "\n",
    "utt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize and normalize using lucem_illud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dialogue_text(utterance):\n",
    "    text = \"\"\n",
    "    speaker = utterance.speaker.id\n",
    "    dialogue = utterance.text\n",
    "\n",
    "    text += f\"{speaker}: {dialogue}\\n\"\n",
    "\n",
    "def get_conversation_text(convo_id):\n",
    "    text = \"\"\n",
    "\n",
    "    for utt in corpus.get_conversation(convo_id).iter_utterances():\n",
    "        text += get_dialogue_text(utt)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|          | 18/6405 [00:00<02:07, 49.90it/s]\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens, however you requested 11695 tokens (11695 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Using tqdm to display a loading bar\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(conversation_ids)):\n\u001b[1;32m---> 38\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# getting the result to handle exceptions if any\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m, in \u001b[0;36mprocess_conversation\u001b[1;34m(convo_id)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_conversation\u001b[39m(convo_id):\n\u001b[0;32m     24\u001b[0m     convo_text \u001b[38;5;241m=\u001b[39m get_conversation_text(convo_id)\n\u001b[1;32m---> 25\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvo_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     corpus\u001b[38;5;241m.\u001b[39mget_conversation(convo_id)\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m embedding\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(text, model)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(text, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-large\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      8\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\site-packages\\openai\\resources\\embeddings.py:113\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    108\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\site-packages\\openai\\_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1199\u001b[0m     )\n\u001b[1;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\site-packages\\openai\\_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\site-packages\\openai\\_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    988\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens, however you requested 11695 tokens (11695 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm  # for the loading bar\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def get_dialogue_text(utterance):\n",
    "    speaker = utterance.speaker.id\n",
    "    dialogue = utterance.text\n",
    "    return f\"{speaker}: {dialogue}\\n\"\n",
    "\n",
    "def get_conversation_text(convo_id):\n",
    "    text = \"\"\n",
    "    for utt in corpus.get_conversation(convo_id).iter_utterances():\n",
    "        text += get_dialogue_text(utt)\n",
    "    return text\n",
    "\n",
    "def process_conversation(convo_id):\n",
    "    convo_text = get_conversation_text(convo_id)\n",
    "    embedding = get_embedding(convo_text)\n",
    "    corpus.get_conversation(convo_id).meta['openai_embedding'] = embedding\n",
    "\n",
    "# List of all conversation IDs in the corpus\n",
    "conversation_ids = [convo.id for convo in corpus.iter_conversations()]\n",
    "\n",
    "\n",
    "\n",
    "num_workers = 25  # Adjust this to the desired number of workers\n",
    "\n",
    "# Using ThreadPoolExecutor with the specified number of workers for parallel processing\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Creating a list of futures\n",
    "    futures = [executor.submit(process_conversation, convo_id) for convo_id in conversation_ids]\n",
    "    \n",
    "    # Using tqdm to display a loading bar\n",
    "    for future in tqdm(as_completed(futures), total=len(conversation_ids)):\n",
    "        _ = future.result()  # getting the result to handle exceptions if any\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_normalize(text):\n",
    "    tokenized_sents = [lucem_illud.word_tokenize(s) for s in lucem_illud.sent_tokenize(text)]\n",
    "    normalized_sents = [lucem_illud.normalizeTokens(s, lemma=False) for s in tokenized_sents]\n",
    "    return tokenized_sents, normalized_sents\n",
    "\n",
    "# Iterate over all utterances in the corpus and apply the function\n",
    "for utterance in corpus.iter_utterances():\n",
    "    text = utterance.text\n",
    "    tokenized, normalized = tokenize_and_normalize(text)\n",
    "    utterance.meta['tokenized_sents'] = tokenized\n",
    "    utterance.meta['normalized_sents'] = normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.story</th>\n",
       "      <th>meta.tokenized_sents</th>\n",
       "      <th>meta.normalized_sents</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>utt_0</th>\n",
       "      <td>0</td>\n",
       "      <td>It's been a long time since we've last seen...</td>\n",
       "      <td>non-character</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_0</td>\n",
       "      <td>main_0_Evil Time Part 1</td>\n",
       "      <td>[[It, 's, been, a, long, time, since, we, 've,...</td>\n",
       "      <td>[[long, time, ve, seen], [time], [ve, teeterin...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_1</th>\n",
       "      <td>1</td>\n",
       "      <td>...consciousness...    Circulation resumed....</td>\n",
       "      <td>Distant Voice</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_1</td>\n",
       "      <td>main_0_Evil Time Part 1</td>\n",
       "      <td>[[consciousness, Circulation, resumed, vitals,...</td>\n",
       "      <td>[[consciousness, circulation, resumed, vitals,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_2</th>\n",
       "      <td>2</td>\n",
       "      <td>......    Doctor...    ...hand!    Take my....</td>\n",
       "      <td>???</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_1</td>\n",
       "      <td>main_0_Evil Time Part 1</td>\n",
       "      <td>[[], [Doctor, hand], [Take, my, Take, my, hand...</td>\n",
       "      <td>[[], [doctor, hand], [hand], [], [emergency], ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_3</th>\n",
       "      <td>3</td>\n",
       "      <td>Amiya! Don't panic, just calm down first!</td>\n",
       "      <td>Medic</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_1</td>\n",
       "      <td>main_0_Evil Time Part 1</td>\n",
       "      <td>[[Amiya], [Do, n't, panic, just, calm, down, f...</td>\n",
       "      <td>[[amiya], [panic, calm]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ah... S-sorry.</td>\n",
       "      <td>Amiya</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_1</td>\n",
       "      <td>main_0_Evil Time Part 1</td>\n",
       "      <td>[[Ah, S, sorry]]</td>\n",
       "      <td>[[ah, s, sorry]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_88488</th>\n",
       "      <td>88488</td>\n",
       "      <td>This mission was originally meant for the La...</td>\n",
       "      <td>???</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_88481</td>\n",
       "      <td>act9mini_Pinus Sylvestris</td>\n",
       "      <td>[[This, mission, was, originally, meant, for, ...</td>\n",
       "      <td>[[mission, originally, meant, lazurites, recom...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_88489</th>\n",
       "      <td>88489</td>\n",
       "      <td>Confirmed... It's a match.</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_88481</td>\n",
       "      <td>act9mini_Pinus Sylvestris</td>\n",
       "      <td>[[Confirmed], [It, 's, a, match]]</td>\n",
       "      <td>[[confirmed], [match]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_88490</th>\n",
       "      <td>88490</td>\n",
       "      <td>Very good.   Do not disappoint us.</td>\n",
       "      <td>???</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_88481</td>\n",
       "      <td>act9mini_Pinus Sylvestris</td>\n",
       "      <td>[[Very, good], [Do, not, disappoint, us]]</td>\n",
       "      <td>[[good], [disappoint]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_88491</th>\n",
       "      <td>88491</td>\n",
       "      <td>It's easy to make a regular Joe disappear, but...</td>\n",
       "      <td>non-character</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_88491</td>\n",
       "      <td>act9mini_Pinus Sylvestris</td>\n",
       "      <td>[[It, 's, easy, to, make, a, regular, Joe, dis...</td>\n",
       "      <td>[[easy, regular, joe, disappear, simple, task,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_88492</th>\n",
       "      <td>88492</td>\n",
       "      <td>Hmph...   *Sigh*... Can't I at least get a l...</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>None</td>\n",
       "      <td>utt_88492</td>\n",
       "      <td>act9mini_Pinus Sylvestris</td>\n",
       "      <td>[[Hmph, Sigh], [Ca, n't, I, at, least, get, a,...</td>\n",
       "      <td>[[hmph, sigh], [little, time, veg], [m, tired]...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88493 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp                                               text  \\\n",
       "id                                                                       \n",
       "utt_0             0     It's been a long time since we've last seen...   \n",
       "utt_1             1     ...consciousness...    Circulation resumed....   \n",
       "utt_2             2     ......    Doctor...    ...hand!    Take my....   \n",
       "utt_3             3          Amiya! Don't panic, just calm down first!   \n",
       "utt_4             4                                     Ah... S-sorry.   \n",
       "...             ...                                                ...   \n",
       "utt_88488     88488    This mission was originally meant for the La...   \n",
       "utt_88489     88489                         Confirmed... It's a match.   \n",
       "utt_88490     88490                 Very good.   Do not disappoint us.   \n",
       "utt_88491     88491  It's easy to make a regular Joe disappear, but...   \n",
       "utt_88492     88492    Hmph...   *Sigh*... Can't I at least get a l...   \n",
       "\n",
       "                 speaker reply_to conversation_id                 meta.story  \\\n",
       "id                                                                             \n",
       "utt_0      non-character     None           utt_0    main_0_Evil Time Part 1   \n",
       "utt_1      Distant Voice     None           utt_1    main_0_Evil Time Part 1   \n",
       "utt_2                ???     None           utt_1    main_0_Evil Time Part 1   \n",
       "utt_3              Medic     None           utt_1    main_0_Evil Time Part 1   \n",
       "utt_4              Amiya     None           utt_1    main_0_Evil Time Part 1   \n",
       "...                  ...      ...             ...                        ...   \n",
       "utt_88488            ???     None       utt_88481  act9mini_Pinus Sylvestris   \n",
       "utt_88489       Platinum     None       utt_88481  act9mini_Pinus Sylvestris   \n",
       "utt_88490            ???     None       utt_88481  act9mini_Pinus Sylvestris   \n",
       "utt_88491  non-character     None       utt_88491  act9mini_Pinus Sylvestris   \n",
       "utt_88492       Platinum     None       utt_88492  act9mini_Pinus Sylvestris   \n",
       "\n",
       "                                        meta.tokenized_sents  \\\n",
       "id                                                             \n",
       "utt_0      [[It, 's, been, a, long, time, since, we, 've,...   \n",
       "utt_1      [[consciousness, Circulation, resumed, vitals,...   \n",
       "utt_2      [[], [Doctor, hand], [Take, my, Take, my, hand...   \n",
       "utt_3      [[Amiya], [Do, n't, panic, just, calm, down, f...   \n",
       "utt_4                                       [[Ah, S, sorry]]   \n",
       "...                                                      ...   \n",
       "utt_88488  [[This, mission, was, originally, meant, for, ...   \n",
       "utt_88489                  [[Confirmed], [It, 's, a, match]]   \n",
       "utt_88490          [[Very, good], [Do, not, disappoint, us]]   \n",
       "utt_88491  [[It, 's, easy, to, make, a, regular, Joe, dis...   \n",
       "utt_88492  [[Hmph, Sigh], [Ca, n't, I, at, least, get, a,...   \n",
       "\n",
       "                                       meta.normalized_sents vectors  \n",
       "id                                                                    \n",
       "utt_0      [[long, time, ve, seen], [time], [ve, teeterin...      []  \n",
       "utt_1      [[consciousness, circulation, resumed, vitals,...      []  \n",
       "utt_2      [[], [doctor, hand], [hand], [], [emergency], ...      []  \n",
       "utt_3                               [[amiya], [panic, calm]]      []  \n",
       "utt_4                                       [[ah, s, sorry]]      []  \n",
       "...                                                      ...     ...  \n",
       "utt_88488  [[mission, originally, meant, lazurites, recom...      []  \n",
       "utt_88489                             [[confirmed], [match]]      []  \n",
       "utt_88490                             [[good], [disappoint]]      []  \n",
       "utt_88491  [[easy, regular, joe, disappear, simple, task,...      []  \n",
       "utt_88492  [[hmph, sigh], [little, time, veg], [m, tired]...      []  \n",
       "\n",
       "[88493 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt_df = corpus.get_utterances_dataframe()\n",
    "\n",
    "utt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/MACSS PROGRAM/30122/MACS-60000-2024-Winter/data/Arknights_plot/corpus\" ## corpus folder \n",
    "corpus.dump(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def get_conversation_chunks(convo_id, max_length=2000):\n",
    "    text = \"\"\n",
    "    chunks = []\n",
    "    \n",
    "    for utt in corpus.get_conversation(convo_id).iter_utterances():\n",
    "        dialogue_text = get_dialogue_text(utt)\n",
    "        # Check if adding this dialogue exceeds the max_length\n",
    "        if len(text + dialogue_text) > max_length:\n",
    "            # Save current chunk and start a new one\n",
    "            chunks.append(text)\n",
    "            text = dialogue_text\n",
    "        else:\n",
    "            text += dialogue_text\n",
    "\n",
    "    # Add the last chunk if it's not empty\n",
    "    if text:\n",
    "        chunks.append(text)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def process_conversation_chunks(convo_id):\n",
    "    chunks = get_conversation_chunks(convo_id)\n",
    "    embeddings = [get_embedding(chunk) for chunk in chunks]\n",
    "    return convo_id, embeddings\n",
    "\n",
    "def save_embeddings_to_csv(embeddings_dict, filename=\"conversation_embeddings.csv\"):\n",
    "    with open(filename, mode=\"w\", newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Text Chunk\", \"Embedding\", \"Convo ID\"])\n",
    "\n",
    "        for convo_id, embeddings_list in embeddings_dict.items():\n",
    "            for i, (text_chunk, embedding) in enumerate(embeddings_list):\n",
    "                # Convert the embedding array into a string\n",
    "                embedding_str = \" \".join(map(str, embedding))\n",
    "                # Write the text chunk, its corresponding embedding, and the conversation ID to the CSV\n",
    "                writer.writerow([text_chunk, embedding_str, convo_id])\n",
    "\n",
    "# # Dictionary to store embeddings with conversation IDs as keys\n",
    "# conversation_embeddings = {}\n",
    "\n",
    "# # Adjust the number of workers based on your system's capabilities\n",
    "# num_workers = 10\n",
    "\n",
    "# # Using ThreadPoolExecutor for parallel processing\n",
    "# with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     # Creating a list of futures\n",
    "#     futures = [executor.submit(process_conversation_chunks, convo_id) for convo_id in conversation_ids]\n",
    "    \n",
    "#     # Using tqdm to display a loading bar\n",
    "#     for future in tqdm(as_completed(futures), total=len(conversation_ids)):\n",
    "#         convo_id, embeddings = future.result()\n",
    "#         # Store embeddings in the dictionary with the conversation ID as the key\n",
    "#         conversation_embeddings[convo_id] = embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/10557 [00:00<04:16, 41.01it/s]\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u300c' in position 16: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Using tqdm to display a loading bar\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures)):\n\u001b[1;32m---> 46\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# getting the result to handle exceptions if any\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m, in \u001b[0;36mprocess_and_write_chunk\u001b[1;34m(convo_id, text_chunk)\u001b[0m\n\u001b[0;32m     26\u001b[0m writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(file)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Write the text chunk, its corresponding embedding, and the conversation ID to the CSV\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvo_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\Lib\\encodings\\cp1252.py:19\u001b[0m, in \u001b[0;36mIncrementalEncoder.encode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u300c' in position 16: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Filename for the CSV output\n",
    "filename = \"conversation_embeddings.csv\"\n",
    "\n",
    "# Initialize a lock for thread-safe writing to the CSV file\n",
    "lock = Lock()\n",
    "\n",
    "# Open the CSV file and write the header\n",
    "with open(filename, mode=\"w\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Text Chunk\", \"Embedding\", \"Convo ID\"])\n",
    "\n",
    "def process_and_write_chunk(convo_id, text_chunk):\n",
    "    # Process the text chunk to obtain the embedding\n",
    "    embedding = get_embedding(text_chunk)\n",
    "    # Convert the embedding array into a string representation\n",
    "    embedding_str = \" \".join(map(str, embedding))\n",
    "    \n",
    "    # Acquire the lock before writing to the CSV file\n",
    "    with lock:\n",
    "        with open(filename, mode=\"a\", newline='', encoding='utf-8') as file: # use utf-8!!\n",
    "            writer = csv.writer(file)\n",
    "            # Write the text chunk, its corresponding embedding, and the conversation ID to the CSV\n",
    "            writer.writerow([text_chunk, embedding_str, convo_id])\n",
    "\n",
    "# Adjust the number of workers based on your system's capabilities\n",
    "num_workers = 10\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # List to keep track of futures\n",
    "    futures = []\n",
    "    \n",
    "    # Iterate through conversation IDs and their text chunks\n",
    "    for convo_id in conversation_ids:\n",
    "        text_chunks = get_conversation_chunks(convo_id)\n",
    "        for text_chunk in text_chunks:\n",
    "            # Submit the processing and writing task for each text chunk\n",
    "            futures.append(executor.submit(process_and_write_chunk, convo_id, text_chunk))\n",
    "\n",
    "    # Using tqdm to display a loading bar\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        _ = future.result()  # getting the result to handle exceptions if any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last processed conversation ID was: utt_88492\n"
     ]
    }
   ],
   "source": [
    "embedding_file_path = \"D:\\\\MACSS PROGRAM\\\\30122\\\\MACS-60000-2024-Winter\\\\conversation_embeddings_1.csv\"\n",
    "def find_last_processed_convo_id(csv_file_path):\n",
    "    last_convo_id = None\n",
    "    try:\n",
    "        with open(csv_file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                if line.strip():  # Check if line is not empty\n",
    "                    last_line = line\n",
    "            # Extract the last conversation ID from the last line\n",
    "            last_convo_id = last_line.split(',')[-1].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the last line of the CSV: {e}\")\n",
    "    return last_convo_id\n",
    "\n",
    "embedding_file_path = \"D:\\\\MACSS PROGRAM\\\\30122\\\\MACS-60000-2024-Winter\\\\conversation_embeddings_1.csv\"\n",
    "last_convo_id = find_last_processed_convo_id(embedding_file_path)\n",
    "print(f\"The last processed conversation ID was: {last_convo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "embedding_file_path = \"D:\\\\MACSS PROGRAM\\\\30122\\\\MACS-60000-2024-Winter\\\\conversation_embeddings_1.csv\"\n",
    "chunk_size = 5000\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(embedding_file_path, chunksize=chunk_size, encoding= 'utf-8'):\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df_embed = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Chunk</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Convo ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ursus Guard:    Curse them... where the hell d...</td>\n",
       "      <td>[0.02075939252972603, -0.020792875438928604, -...</td>\n",
       "      <td>utt_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amiya:    ...    I understand. I know this is ...</td>\n",
       "      <td>[0.01998366229236126, 0.007341510150581598, -0...</td>\n",
       "      <td>utt_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amiya:    I'd like... to give it a try.    Eve...</td>\n",
       "      <td>[0.031356941908597946, -0.007000225596129894, ...</td>\n",
       "      <td>utt_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amiya:    That's right. It is not enough to on...</td>\n",
       "      <td>[0.0247239638119936, -0.0342143252491951, -0.0...</td>\n",
       "      <td>utt_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dobermann:   No doubt about it. A Catastrophe ...</td>\n",
       "      <td>[0.024575579911470413, -0.018330411985516548, ...</td>\n",
       "      <td>utt_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10521</th>\n",
       "      <td>'Lazurite':   You see, it would be very inconv...</td>\n",
       "      <td>[-0.010119310580193996, -0.062104638665914536,...</td>\n",
       "      <td>utt_88477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10522</th>\n",
       "      <td>non-character: It's easy to make a regular Joe...</td>\n",
       "      <td>[0.05466289445757866, -0.04355096444487572, -0...</td>\n",
       "      <td>utt_88491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10523</th>\n",
       "      <td>non-character: And then he leaves. And there's...</td>\n",
       "      <td>[0.04670620709657669, -0.029989928007125854, -...</td>\n",
       "      <td>utt_88480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10524</th>\n",
       "      <td>???:   The arena's too small for you, isn't it...</td>\n",
       "      <td>[0.03681131452322006, -0.04066556319594383, -0...</td>\n",
       "      <td>utt_88453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10525</th>\n",
       "      <td>Platinum:   Hmph...   *Sigh*... Can't I at lea...</td>\n",
       "      <td>[-0.0048131211660802364, -0.025092797353863716...</td>\n",
       "      <td>utt_88492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10526 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Text Chunk  \\\n",
       "0      Ursus Guard:    Curse them... where the hell d...   \n",
       "1      Amiya:    ...    I understand. I know this is ...   \n",
       "2      Amiya:    I'd like... to give it a try.    Eve...   \n",
       "3      Amiya:    That's right. It is not enough to on...   \n",
       "4      Dobermann:   No doubt about it. A Catastrophe ...   \n",
       "...                                                  ...   \n",
       "10521  'Lazurite':   You see, it would be very inconv...   \n",
       "10522  non-character: It's easy to make a regular Joe...   \n",
       "10523  non-character: And then he leaves. And there's...   \n",
       "10524  ???:   The arena's too small for you, isn't it...   \n",
       "10525  Platinum:   Hmph...   *Sigh*... Can't I at lea...   \n",
       "\n",
       "                                               Embedding   Convo ID  \n",
       "0      [0.02075939252972603, -0.020792875438928604, -...      utt_1  \n",
       "1      [0.01998366229236126, 0.007341510150581598, -0...      utt_1  \n",
       "2      [0.031356941908597946, -0.007000225596129894, ...      utt_1  \n",
       "3      [0.0247239638119936, -0.0342143252491951, -0.0...      utt_1  \n",
       "4      [0.024575579911470413, -0.018330411985516548, ...      utt_1  \n",
       "...                                                  ...        ...  \n",
       "10521  [-0.010119310580193996, -0.062104638665914536,...  utt_88477  \n",
       "10522  [0.05466289445757866, -0.04355096444487572, -0...  utt_88491  \n",
       "10523  [0.04670620709657669, -0.029989928007125854, -...  utt_88480  \n",
       "10524  [0.03681131452322006, -0.04066556319594383, -0...  utt_88453  \n",
       "10525  [-0.0048131211660802364, -0.025092797353863716...  utt_88492  \n",
       "\n",
       "[10526 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def string_to_vector(embedding_str):\n",
    "    # Split the string by spaces and convert each element to float\n",
    "    return np.array([float(num) for num in embedding_str.split()])\n",
    "df_embed['Embedding'] = df_embed['Embedding'].apply(string_to_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embed['Embedding'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path= 'D:\\\\MACSS PROGRAM\\\\30122\\\\MACS-60000-2024-Winter\\\\data\\\\Arknights_plot\\\\corpus\\\\conversation_embeddings.csv'\n",
    "\n",
    "df_embed.to_csv(save_path + 'conversation_embeddings.csv', index=False) # don't use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ast  # for converting embeddings saved as strings back to arrays\n",
    "from openai import OpenAI # for calling the OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "import os # for getting API token from env variable OPENAI_API_KEY\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"Text Chunk\"], relatedness_fn(query_embedding, row[\"Embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\MACSS PROGRAM\\\\30122\\\\MACS-60000-2024-Winter\\\\data\\\\Arknights_plot\\\\corpus\\\\conversation_embeddings.csv'\n",
    "df_embed = pd.read_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ 0.02075939 -0.02079288 -0.00999464 ...  0.00383798 -0.00765921\\n -0.00360569]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embed[\"Embedding\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def string_to_nparray(s):\n",
    "#     # Remove brackets and newline characters\n",
    "#     cleaned_str = s.strip('[]\\n')\n",
    "    \n",
    "#     # Split the string by spaces, filter out empty strings, and convert to float\n",
    "#     float_list = [float(item) for item in cleaned_str.split(' ') if item not in ['', '...']]\n",
    "    \n",
    "#     # Convert the list to a numpy array\n",
    "#     return np.array(float_list)\n",
    "# df_embed['Embedding'] = df_embed['Embedding'].apply(string_to_nparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embed['Embedding'][0].shape # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Reunion Member:    That's right, her assault went very smoothly!    Should we also retreat?\\nSkullshatterer:    ...    Send a signal to Talulah.\\nReunion Member:    Roger!\\nSkullshatterer:    ...We're pulling back.    Hmph. Rhodes Island cowards...    The next time we meet... will be at your execution.\\nAmiya:    Reunion... is retreating?\\nFranka:    They're retreating very rapidly. Something must have changed with their plans.    Despite all that talk, they sure know how to run away.\\nAmiya:    ...    Something... doesn't feel right.\\nLiskarm:    Are you saying...\\nAmiya:    ...!    That they were only here to stall us...?    If that's the case...    Oh no, the L.G.D. is in trouble!    ...We have to help Madam Ch'en right now!    Franka, call the recon squad back immediately!    Liskarm, try to get in touch with Madam Ch'en!\\nCh'en:    Where's the Special Operations Division? Their reinforcements are supposed to be here by now!\\nL.G.D. Agent:    We were just notified that they've been stalled by Reunion...!\\nCh'en:    How's that possible? Reunion is nothing more than a gang of unruly thugs!\\nL.G.D. Agent:    ...And they were only facing... a single enemy...\\nCh'en:    ...    Unless...\\nCh'en:    Looks like you had a rough time as well.\\nAmiya:    Madam Ch'en, what happened here?\\nCh'en:    We were ambushed by Reunion.    We were caught in a withering assault with no reinforcements. They easily routed our forces.\\nAmiya:    And Misha...?\\nCh'en:    She was taken away by a woman dressed in red.    I really should have...\\nAmiya:   ...?\\nCh'en:    Nevermind.\\nAmiya:    ...    Madam Ch'en, why is Misha so special?    If you keep hiding things from us, it's only going to be harder and harder for us to continue working together.\\nCh'en:    I have no obligation to tell you.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Reunion Member:    Nngh... Guhh...    Uaaagh!    It hurts... It huuurrtsssss...    Aaagh... Aaaargh! It itches! It itches!!    Graaah?!!    Rhodes... Rhodes Island!    Enemy... Enemy!!\\nJessica:    What...! Wh-what's going on...    The enemies we just defeated are standing back up...?\\nMephisto:    What? Are you done already?\\nFrostleaf:    There's a glow... coming from that guy's staff...?\\nMephisto:    I haven't even done anything yet.\\nJessica:    And... they've got a lot more reinforcements coming...\\nMeteorite:    Curse you...!    Right now, I can only pray that this round can kill the enemy leader...!\\nFrostleaf:    Don't.\\nMephisto:    Haha... Do you really have time for a strategy meeting in your position?    So much self-confidence.\\nMeteorite:    Hmph. I'll teach you a lesson with this shot...\\nFrostleaf:    No, Meteorite. Don't.\\nMeteorite:    Tsk...! Why?!\\nFrostleaf:    We need to retreat.    I can feel it...    It's them. They're here.\\nMephisto:    Ohh? You're not going to shoot?    What a pity.    You know, you won't get another chance.\\nMeteorite:    Is he leaving? But--\\nFrostleaf:    Meteorite! Aim at that collapsing building to the west, now! At least we can distract the enemy to buy us some time!\\nMeteorite:    ...This is our only option! I'll do it!\\nFrostleaf:    Jessica, start running.\\nJessica:    Huh?\\nFrostleaf:    ...The Yetis are here.\\nJessica:    Wait...    S-so cold...\\nFrostleaf:    ... ...Let's go.    Now.\\nMeteorite:    ...Jessica.    She's right.    We need to get out of here...!\\nFrostleaf:    Amiya, can you hear me?    Hello? Hello?\\nMeteorite:    Just go! I'll cover you!\\nFrostleaf:    Listen, Amiya.    ...Do not come.    These ruins are...\\nAmiya:    Frostleaf? Frostleaf?!    What's going on...\\nGuard:    Amiya! This is the 2nd Recon Squad....    We're currently retreating! But, the enemy...    Reunion...    ...\\nAmiya:    It cut out again?    3rd Recon Squad! Do you copy? 3rd Recon Squad!    ...\\nCh'en:    ...\\nKal'tsit:    Amiya.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Amiya: The revenant...\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Amiya:    Ah, Doctor?    Were you waiting for me this whole time...    Sorry to have kept you waiting.    Hmm? My complexion looks different from when I left?    ...    Some things happened.    I feel like...    Perhaps Madam Ch'en has her own way of looking at things.    Even though her words are harsh, and she has done things that I can't accept...    Maybe... the difference between us isn't that big.    She has her responsibilities.    Oh... I understand now...    She also has her share of burdens to bear.    Perhaps I also...\\nAmiya:    Is that so...    I... just didn't have other choices.\\nAmiya:    ...I suppose all these consequences were the results of my persistence.    Doctor, there's no need... to try to comfort me.    Actually, I'm well aware of this.    But what I don't know...    What I don't know, is how long we have to keep going before this world begins to change.    But, what I do know for sure...    Is that I won't give up.    I'll always bear the consequences of my actions, because... I chose this path.    Doctor...    Will you... stay by my side?    Even though... this guilt will always stay with me...    The regret of not being able to bring everyone with me. The regret of not being able to save my friends...    But I must face reality.    With everyone in Rhodes Island...    Hmm? A message from Dr. Kal'tsit...    Dr. Kal'tsit? Did you need something?\\nKal'tsit:    Amiya, I've received communications from a few recon teams.    The situation has changed for the worse.\\nAmiya:    Okay, I'll be right there.\\nReunion Member:    Get moving! ...\\nJessica:    What's going on...?\\nFrostleaf:    (Don't make a sound!)\\nJessica:    (Nnnh---)\\nFrostleaf:    (Are they still around?)\\nMeteorite:    (They're still here...!)    (They seem to searching for something...)    (A Reunion member is headed our way! We need to hide!)\\nReunion Member:    ...    Must be my imagination.\\nFrostleaf:    (Can you get a clear shot on him?)\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedness=0.583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Misha:    I don't know anything about this 'Reunion' that you're talking about, but...    But I do know the L.G.D., and I've seen how they treat the Infected. If you wanted me to capture me from the beginning, you should've just said it.\\nAmiya:    I'm sorry... But, that's really not our intention. I know there are still some misunderstandings that have to be worked out.    But no matter how bad you think we are... Please, just bear with us a bit longer.    Your safety takes priority over how you feel.    I'll explain everything if I get the chance.    After all, there are still things that I want to know...\\nMisha:    ...\\nTexas:    ...    Rhodes Island sure is taking their time.    Oh...?\\nReunion Member:    We're almost at the interception point!\\nTexas:    Tch, finally... I just finished unpacking.    What a waste.\\nReunion Member:    Hurry up! Those in the back, follow more closely!\\nTexas:    Hey, masked person over there.\\nReunion Member:    Who is it? !    What do you want?\\nTexas:    All of you, come at me. I'm short on time.\\nFranka:    Amiya, Texas from Penguin Logistics has returned.\\nAmiya:    Ahh... what a relief!\\nTexas:    I have an update here.    I just took care of some guys who called themselves 'Reunion.'    ... But there are a lot more of them coming.    Reunion has come out of hiding and are starting to move in groups.\\nAmiya:    It's as I feared...    Reunion has already infiltrated Lungmen through the slums...    And their target... is the same as ours.    Otherwise, there would be no reason for them to come after Rhodes Island.\\nLiskarm:    Miss Misha is carrying secrets that only Lungmen and Reunion know.    We're caught in a disadvantageous situation.\\nFranka:    Things aren't looking good for us right now.    I'll really have to poke that officer's pretty little face later to find out what's actually going on.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "strings, relatednesses = strings_ranked_by_relatedness(\"what is Reunion from Amiya's perspective\", df_embed, top_n=5)\n",
    "for string, relatedness in zip(strings, relatednesses):\n",
    "    print(f\"{relatedness=:.3f}\")\n",
    "    display(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n",
    "    introduction = \"\"\"\n",
    "    These are some dialogue from the fictional world.\n",
    "    Try to infer about the world based on the dialogue and try your best to answer the questions.\n",
    "    You can ask for more information.\n",
    "    \"\"\"\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\nDialogues:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df_embed,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500, #consider budget\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions about the fictional world of 'Arknights'.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The leader of the Reunion is known as Talulah.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"Who is the leader of the Reunion?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From the dialogues provided, it is clear that Reunion is a significant faction within the world of Arknights. Amiya's perspective on Reunion seems to be complex and multifaceted. She acknowledges that Reunion members are individuals who are facing difficult circumstances and are seeking refuge from various threats, including the Sarkaz and guerrillas. Amiya shows empathy towards Reunion members, understanding their fears and concerns.\\n\\nAmiya also recognizes the actions of Reunion, such as infiltrating Lungmen and causing turmoil, as well as their clashes with Rhodes Island and the L.G.D. She seems to view Reunion as a group that is driven by desperation and a sense of being cornered, leading them to take extreme measures.\\n\\nDespite the conflicts and differences between Rhodes Island and Reunion, Amiya tries to find common ground and offers assistance to Reunion members who are willing to protect bystander Infected individuals. She emphasizes the importance of understanding the truth about Reunion rather than relying on hearsay or rumors.\\n\\nOverall, from Amiya's perspective, Reunion appears to be a group of individuals who are struggling to survive in a hostile world, making choices that may not always align with Rhodes Island's values but are driven by their own circumstances and fears. Amiya's approach towards Reunion reflects her compassion and desire to find peaceful resolutions, even in the midst of conflict.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"Try to talk about what is reunion from Amiya's perspective.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the dialogues provided, it seems that Sarkaz and Sankta are two distinct races within the world of Arknights with significant cultural and historical differences:\\n\\n1. **Sarkaz**:\\n   - The Sarkaz are depicted as a proud and fierce race who have faced oppression, displacement, and conflict throughout their history.\\n   - They are shown to have a strong sense of identity and unity, as seen in their resistance against invaders and their determination to rebuild their homeland.\\n   - The Sarkaz are associated with traits such as rage, vengeance, and a history of conflict with other races, particularly the Sankta.\\n   - There are references to the Sarkaz being victims of slaughter, oppression, and displacement, leading to a deep-rooted sense of injustice and a desire for retribution.\\n\\n2. **Sankta**:\\n   - The Sankta are portrayed as a more established and privileged race, with a presence in holy cities like Laterano.\\n   - They are shown to have a religious and hierarchical society, with references to saints, cardinals, and the Church.\\n   - The Sankta are depicted as having a sense of superiority or exclusivity, as seen in their treatment of other races, particularly the Sarkaz.\\n   - There are mentions of the Sankta\\'s disdain or discrimination towards the Sarkaz, labeling them as \"cursed devils\" and perpetuating a long-standing conflict between the two races.\\n\\nIn summary, the differences between Sarkaz and Sankta in the world of Arknights include their cultural backgrounds, societal roles, historical experiences, and attitudes towards each other. The Sarkaz are portrayed as a marginalized and oppressed race seeking justice and retribution, while the Sankta are depicted as a privileged and exclusive society with a history of conflict and discrimination towards the Sarkaz.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What is the differences between Sarkaz and Sankta?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
